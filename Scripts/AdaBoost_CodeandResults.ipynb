{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#General structure:\n",
    "#-Tune model on training data via a grid search\n",
    "#-Run that model on stacked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import munged data\n",
    "train_m = pd.read_csv('train_starting.csv', index_col=0)\n",
    "test_m = pd.read_csv('test_starting.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'date_account_created', 'timestamp_first_active', 'date_first_booking', 'gender', 'age', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser', 'country_destination', 'lag_account_created', 'lag_first_active', 'lag_account_created_first_active', 'bookings', 'population_in_thousands', 'sum_secs_elapsed', 'counts']\n"
     ]
    }
   ],
   "source": [
    "print list(train_m.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove date variables (leaving only the time-lag variables involving dates)\n",
    "\n",
    "excl = list(train_m.columns)\n",
    "toremove = ['id', 'date_account_created', 'timestamp_first_active', 'date_first_booking', 'population_in_thousands',\n",
    "            'lag_account_created', 'bookings', 'lag_first_active', \n",
    "            #'lag_account_created_first_active', \n",
    "              'country_destination'] \n",
    "map(lambda x: excl.remove(x), toremove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_xcl = train_m.loc[:, excl]\n",
    "test_xcl = test_m.loc[:, excl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.py:839: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \"columns will be omitted.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#Concatenate data in order to dummify variables\n",
    "frames = [train_xcl, test_xcl]\n",
    "all_data = pd.concat(frames)\n",
    "all_data = all_data.T.to_dict().values()\n",
    "train_xdic = train_xcl.T.to_dict().values()\n",
    "test_xdic = test_xcl.T.to_dict().values()\n",
    "\n",
    "#Proper format for AdaBoost (dummify variables)\n",
    "vec = DictVectorizer()\n",
    "vec.fit(all_data)\n",
    "train_xvec = vec.transform(train_xdic)\n",
    "test_xvec = vec.transform(test_xdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Response variable\n",
    "train_y = train_m.loc[:,'country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "#Transform response variable\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y)\n",
    "train_ytrans = le.transform(train_y)\n",
    "print type(train_ytrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainx_vecmiss = pd.DataFrame(train_xvec.toarray()).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.grid_search as gs\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# The next few cells perform a grid search for AdaBoost parameters\n",
    "grid_param = [{'learning_rate': [.01], 'n_estimators': [100, 200, 300, 600]}]\n",
    "\n",
    "grid_search = gs.GridSearchCV(model, grid_param, cv=5).fit(trainx_vecmiss, train_ytrans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.58347, std: 0.00004, params: {'n_estimators': 100, 'learning_rate': 0.01},\n",
       " mean: 0.58347, std: 0.00004, params: {'n_estimators': 200, 'learning_rate': 0.01},\n",
       " mean: 0.58347, std: 0.00004, params: {'n_estimators': 300, 'learning_rate': 0.01},\n",
       " mean: 0.59740, std: 0.01037, params: {'n_estimators': 600, 'learning_rate': 0.01}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_param = [{'learning_rate': [.01, .001, .0001], 'n_estimators': [600]}]\n",
    "\n",
    "grid_search = gs.GridSearchCV(model, grid_param, cv=5).fit(trainx_vecmiss, train_ytrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.59740, std: 0.01037, params: {'n_estimators': 600, 'learning_rate': 0.01},\n",
       " mean: 0.58347, std: 0.00004, params: {'n_estimators': 600, 'learning_rate': 0.001},\n",
       " mean: 0.58347, std: 0.00004, params: {'n_estimators': 600, 'learning_rate': 0.0001}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_param = [{'learning_rate': [.01], 'n_estimators': [450, 500, 550, 600, 650]}]\n",
    "\n",
    "grid_search = gs.GridSearchCV(model, grid_param, cv=5).fit(trainx_vecmiss, train_ytrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.58660, std: 0.00604, params: {'n_estimators': 450, 'learning_rate': 0.01},\n",
       " mean: 0.59339, std: 0.01087, params: {'n_estimators': 500, 'learning_rate': 0.01},\n",
       " mean: 0.59491, std: 0.01049, params: {'n_estimators': 550, 'learning_rate': 0.01},\n",
       " mean: 0.59740, std: 0.01037, params: {'n_estimators': 600, 'learning_rate': 0.01},\n",
       " mean: 0.60216, std: 0.01198, params: {'n_estimators': 650, 'learning_rate': 0.01}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_param = [{'learning_rate': [.01, .001], 'n_estimators': [650]}]\n",
    "\n",
    "grid_search = gs.GridSearchCV(model, grid_param, cv=5).fit(trainx_vecmiss, train_ytrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.60216, std: 0.01198, params: {'n_estimators': 650, 'learning_rate': 0.01},\n",
       " mean: 0.58347, std: 0.00004, params: {'n_estimators': 650, 'learning_rate': 0.001}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_\n",
    "\n",
    "#Optimal parameters are n_estimators = 650, learning_rate = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'gender', 'age', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser', 'country_destination', 'sum_secs_elapsed', 'counts', 'pred_lag_account_created', 'pred_lag_first_active', 'pred_bookings']\n"
     ]
    }
   ],
   "source": [
    "#Import stacked data\n",
    "\n",
    "trainf = pd.read_csv('training_for_final_models.csv')\n",
    "testf = pd.read_csv('test_for_final_models.csv')\n",
    "print list(trainf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>country_destination</th>\n",
       "      <th>sum_secs_elapsed</th>\n",
       "      <th>counts</th>\n",
       "      <th>pred_lag_account_created</th>\n",
       "      <th>pred_lag_first_active</th>\n",
       "      <th>pred_bookings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gxn3p5htnn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB</td>\n",
       "      <td>NB</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>820tgsjxq7</td>\n",
       "      <td>MALE</td>\n",
       "      <td>35-39</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>seo</td>\n",
       "      <td>google</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>same day</td>\n",
       "      <td>before</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ft3gnwmtx</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>55-59</td>\n",
       "      <td>basic</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>IE</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greater 1 day</td>\n",
       "      <td>greater 1 day</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bjjt8pjhuk</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>40-44</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB</td>\n",
       "      <td>NB</td>\n",
       "      <td>waited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87mebub9p4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40-44</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greater 1 day</td>\n",
       "      <td>greater 1 day</td>\n",
       "      <td>NB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  gender    age signup_method  signup_flow language  \\\n",
       "0  gxn3p5htnn     NaN    NaN      facebook            0       en   \n",
       "1  820tgsjxq7    MALE  35-39      facebook            0       en   \n",
       "2  4ft3gnwmtx  FEMALE  55-59         basic            3       en   \n",
       "3  bjjt8pjhuk  FEMALE  40-44      facebook            0       en   \n",
       "4  87mebub9p4     NaN  40-44         basic            0       en   \n",
       "\n",
       "  affiliate_channel affiliate_provider first_affiliate_tracked signup_app  \\\n",
       "0            direct             direct               untracked        Web   \n",
       "1               seo             google               untracked        Web   \n",
       "2            direct             direct               untracked        Web   \n",
       "3            direct             direct               untracked        Web   \n",
       "4            direct             direct               untracked        Web   \n",
       "\n",
       "  first_device_type first_browser country_destination  sum_secs_elapsed  \\\n",
       "0       Mac Desktop        Chrome                 NDF               NaN   \n",
       "1       Mac Desktop        Chrome                 NDF               NaN   \n",
       "2   Windows Desktop            IE                  US               NaN   \n",
       "3       Mac Desktop       Firefox               other               NaN   \n",
       "4       Mac Desktop        Chrome                  US               NaN   \n",
       "\n",
       "   counts pred_lag_account_created pred_lag_first_active pred_bookings  \n",
       "0     NaN                       NB                    NB            NB  \n",
       "1     NaN                 same day                before         early  \n",
       "2     NaN            greater 1 day         greater 1 day            NB  \n",
       "3     NaN                       NB                    NB        waited  \n",
       "4     NaN            greater 1 day         greater 1 day            NB  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'age',\n",
       " 'signup_method',\n",
       " 'signup_flow',\n",
       " 'language',\n",
       " 'affiliate_channel',\n",
       " 'affiliate_provider',\n",
       " 'first_affiliate_tracked',\n",
       " 'signup_app',\n",
       " 'first_device_type',\n",
       " 'first_browser',\n",
       " 'sum_secs_elapsed',\n",
       " 'counts',\n",
       " 'pred_lag_account_created',\n",
       " 'pred_lag_first_active',\n",
       " 'pred_bookings']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excl = list(trainf.columns)\n",
    "toremove = ['id', 'country_destination'] \n",
    "map(lambda x: excl.remove(x), toremove)\n",
    "excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_xcl = trainf.loc[:, excl]\n",
    "test_xcl = testf.loc[:, excl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "#Transform data to format for AdaBoost (dummify variables)\n",
    "frames = [train_xcl, test_xcl]\n",
    "all_data = pd.concat(frames)\n",
    "all_data = all_data.T.to_dict().values()\n",
    "train_xdic = train_xcl.T.to_dict().values()\n",
    "test_xdic = test_xcl.T.to_dict().values()\n",
    "\n",
    "vec = DictVectorizer()\n",
    "vec.fit(all_data)\n",
    "train_xvec = vec.transform(train_xdic)\n",
    "test_xvec = vec.transform(test_xdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y = trainf.loc[:,'country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_y)\n",
    "train_ytrans = le.transform(train_y)\n",
    "print type(train_ytrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainx_vecmiss = pd.DataFrame(train_xvec.toarray()).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model2 = AdaBoostClassifier()\n",
    " \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#ndcg is the objective function of the Airbnb Kaggle competition. This was taken from a script form Kaggle.\n",
    "#ndcg_score is a scoring object using the ndcg score function.\n",
    "#dcg_score is a helper function.\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    " \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "\n",
    " Parameters\n",
    " ----------\n",
    " y_true : array, shape = [n_samples]\n",
    "     Ground truth (true relevance labels).\n",
    " y_score : array, shape = [n_samples, n_classes]\n",
    "     Predicted scores.\n",
    " k : int\n",
    "     Rank.\n",
    "\n",
    " Returns\n",
    " -------\n",
    " score : float\n",
    " \"\"\"\n",
    " order = np.argsort(y_score)[::-1]\n",
    " y_true = np.take(y_true, order[:k])\n",
    "\n",
    " gain = 2 ** y_true - 1\n",
    "\n",
    " discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    " return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    " \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    " Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    " recommendation system based on the graded relevance of the recommended\n",
    " entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    " ranking of the entities.\n",
    "\n",
    " Parameters\n",
    " ----------\n",
    " ground_truth : array, shape = [n_samples]\n",
    "     Ground truth (true labels represended as integers).\n",
    " predictions : array, shape = [n_samples, n_classes]\n",
    "     Predicted probabilities.\n",
    " k : int\n",
    "     Rank.\n",
    "\n",
    " Returns\n",
    " -------\n",
    " score : float\n",
    "\n",
    " Example\n",
    " -------\n",
    " >>> ground_truth = [1, 0, 2]\n",
    " >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    " >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    " 1.0\n",
    " >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    " >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    " 0.6666666666\n",
    " \"\"\"\n",
    " lb = LabelBinarizer()\n",
    " lb.fit(range(len(predictions) + 1))\n",
    " T = lb.transform(ground_truth)\n",
    "\n",
    " scores = []\n",
    "\n",
    " # Iterate over each y_true and compute the DCG score\n",
    " for y_true, y_score in zip(T, predictions):\n",
    "     actual = dcg_score(y_true, y_score, k)\n",
    "     best = dcg_score(y_true, y_true, k)\n",
    "     score = float(actual) / float(best)\n",
    "     scores.append(score)\n",
    "\n",
    " return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba= True, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Use optimal parameters previously found to predict country destination on stacked data.\n",
    "\n",
    "import sklearn.grid_search as gs\n",
    "\n",
    "#max_depth_values = [5, 6, 7]\n",
    "learning_rate_values = [.01]\n",
    "# subsample_values = [0.7]\n",
    "# colsample_bytree_values = [0.7]\n",
    "n_estimators = [650]\n",
    "# gamma = [0]\n",
    "\n",
    "params = {'learning_rate': learning_rate_values,\n",
    "        'n_estimators' : n_estimators}\n",
    "\n",
    "grid = gs.GridSearchCV(model2, params, scoring=ndcg_scorer, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.81753, std: 0.00607, params: {'n_estimators': 650, 'learning_rate': 0.01}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainx_vecmiss, train_ytrans)\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testx_vecmiss = pd.DataFrame(test_xvec.toarray()).fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = grid.predict_proba(testx_vecmiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.head of                 id country\n",
      "0       5uwns89zht     NDF\n",
      "1       5uwns89zht      US\n",
      "2       5uwns89zht   other\n",
      "3       5uwns89zht      FR\n",
      "4       5uwns89zht      IT\n",
      "5       jtl0dijy2j     NDF\n",
      "6       jtl0dijy2j      US\n",
      "7       jtl0dijy2j   other\n",
      "8       jtl0dijy2j      FR\n",
      "9       jtl0dijy2j      IT\n",
      "10      xx0ulgorjt     NDF\n",
      "11      xx0ulgorjt      US\n",
      "12      xx0ulgorjt   other\n",
      "13      xx0ulgorjt      FR\n",
      "14      xx0ulgorjt      IT\n",
      "15      6c6puo6ix0     NDF\n",
      "16      6c6puo6ix0      US\n",
      "17      6c6puo6ix0   other\n",
      "18      6c6puo6ix0      FR\n",
      "19      6c6puo6ix0      IT\n",
      "20      czqhjk3yfe     NDF\n",
      "21      czqhjk3yfe      US\n",
      "22      czqhjk3yfe   other\n",
      "23      czqhjk3yfe      FR\n",
      "24      czqhjk3yfe      IT\n",
      "25      szx28ujmhf      US\n",
      "26      szx28ujmhf     NDF\n",
      "27      szx28ujmhf   other\n",
      "28      szx28ujmhf      FR\n",
      "29      szx28ujmhf      IT\n",
      "...            ...     ...\n",
      "310450  8yvhec201j     NDF\n",
      "310451  8yvhec201j      US\n",
      "310452  8yvhec201j   other\n",
      "310453  8yvhec201j      FR\n",
      "310454  8yvhec201j      IT\n",
      "310455  cv0na2lf5a     NDF\n",
      "310456  cv0na2lf5a      US\n",
      "310457  cv0na2lf5a   other\n",
      "310458  cv0na2lf5a      FR\n",
      "310459  cv0na2lf5a      IT\n",
      "310460  zp8xfonng8     NDF\n",
      "310461  zp8xfonng8      US\n",
      "310462  zp8xfonng8   other\n",
      "310463  zp8xfonng8      FR\n",
      "310464  zp8xfonng8      IT\n",
      "310465  fa6260ziny     NDF\n",
      "310466  fa6260ziny      US\n",
      "310467  fa6260ziny   other\n",
      "310468  fa6260ziny      FR\n",
      "310469  fa6260ziny      IT\n",
      "310470  87k0fy4ugm     NDF\n",
      "310471  87k0fy4ugm      US\n",
      "310472  87k0fy4ugm   other\n",
      "310473  87k0fy4ugm      FR\n",
      "310474  87k0fy4ugm      IT\n",
      "310475  9uqfg8txu3      US\n",
      "310476  9uqfg8txu3     NDF\n",
      "310477  9uqfg8txu3   other\n",
      "310478  9uqfg8txu3      FR\n",
      "310479  9uqfg8txu3      IT\n",
      "\n",
      "[310480 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "#Print out top 5 predicted countries\n",
    "\n",
    "test_id = testf['id']\n",
    "\n",
    "  \n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(test_id)):\n",
    "   idx = test_id[i]\n",
    "   ids += [idx] * 5\n",
    "   cts += le.inverse_transform(np.argsort(predictions[i])[::-1])[:5].tolist()\n",
    "  \n",
    "sub1 = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "print sub1.head\n",
    "sub1.to_csv('sub1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
